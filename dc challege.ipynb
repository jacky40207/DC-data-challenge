{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dc challege-副.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9rh7p8_PjcQp"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import random\n","from sklearn import preprocessing \n","\n","def train_y(y):\n","    y_one=np.zeros(10)\n","    y_one[y]=1\n","    return y_one\n","test_data=pd.read_csv('/content/drive/Shareddrives/dc競賽/test_data.csv') # DataFram:528x6001\n","train=pd.read_csv('/content/drive/Shareddrives/dc競賽/train.csv') # DataFram:792x6002\n","\n","def data_processing(dataset):\n","    data_pre=dataset.iloc[:,1:6001]\n","    label_pre=dataset.iloc[:,6001]\n","\n","    data=[]\n","    label=[]\n","    \n","    for i in range(data_pre.shape[0]):\n","        for j in range(10):\n","            data.append(data_pre.iloc[i][j*300:j*300+3000])\n","            label.append(label_pre.iloc[i])\n","    \n","    data=np.array(data)\n","    label=np.array(label)\n","      \n","    label_transform=np.array([train_y(label[i]) for i in range(len(label))])\n","\n","    index=[i for i in range(len(data))]\n","    np.random.shuffle(index)\n","    \n","    trX=data[index[:]]\n","    trY=label_transform[index[:]]\n","    teX=data[index[:]]\n","    teY=label_transform[index[:]]        \n","            \n","    return trX,trY,teX,teY\n","            \n","trX,trY,teX,teY=data_processing(train)\n","\n","def data_test_processing(dataset):\n","    data_pre=dataset.iloc[:,1:6001] # float64 mnist:float32\n","\n","    test_data=[]\n","    \n","    for i in range(data_pre.shape[0]):\n","        for j in range(10):\n","            test_data.append(data_pre.iloc[i][j*300:j*300+3000])\n","    \n","    test_data=np.array(test_data)\n","    \n","    return test_data\n","            \n","test_data=data_test_processing(test_data)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvM-hFSrluDt"},"source":["import tensorflow.keras\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Input\r\n","from tensorflow.keras.layers import Conv1D,MaxPooling1D\r\n","from tensorflow.keras.optimizers import SGD\r\n","from tensorflow.keras import regularizers\r\n","import numpy as np\r\n","import os\r\n","\r\n","\r\n","from tensorflow.keras import backend as K\r\n","\r\n","def recall(y_true, y_pred):\r\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n","    recall = true_positives / (possible_positives + K.epsilon())\r\n","    return recall\r\n","\r\n","def precision(y_true, y_pred):\r\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n","    precision = true_positives / (predicted_positives + K.epsilon())\r\n","    return precision\r\n","\r\n","def f1(y_true, y_pred):\r\n","    def recall(y_true, y_pred):\r\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n","        recall = true_positives / (possible_positives + K.epsilon())\r\n","        return recall\r\n"," \r\n","    def precision(y_true, y_pred):\r\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n","        precision = true_positives / (predicted_positives + K.epsilon())\r\n","        return precision\r\n","    precision = precision(y_true, y_pred)\r\n","    recall = recall(y_true, y_pred)\r\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\r\n","\r\n","if K.image_data_format()=='channel_first':\r\n","    trX=trX.reshape(trX.shape[0],1,3000)\r\n","    teX=teX.reshape(teX.shape[0],1,3000)\r\n","    test_data=test_data.reshape(test_data.shape[0],1,3000)\r\n","    input_shape=(1,3000)\r\n","else:\r\n","    trX=trX.reshape(trX.shape[0],3000,1)\r\n","    teX=teX.reshape(teX.shape[0],3000,1)\r\n","    test_data=test_data.reshape(test_data.shape[0],3000,1)\r\n","    input_shape=(3000,1)\r\n","    \r\n","batch_size=128\r\n","num_classes=10\r\n","epochs=5000\r\n","\r\n","\r\n","model=Sequential()\r\n","model.add(Conv1D(16,kernel_size=3,strides=1,\r\n","                 activation='relu',\r\n","                 input_shape=input_shape))\r\n","model.add(Conv1D(16,kernel_size=3,strides=1,\r\n","                 activation='relu',))\r\n","model.add(Conv1D(16,kernel_size=3,strides=1,\r\n","                 activation='relu',))\r\n","model.add(MaxPooling1D(pool_size=2))\r\n","model.add(Conv1D(32,kernel_size=3,strides=1,\r\n","                 activation='relu'))\r\n","model.add(Conv1D(32,kernel_size=3,strides=1,\r\n","                 activation='relu'))\r\n","model.add(Conv1D(32,kernel_size=3,strides=1,\r\n","                 activation='relu'))\r\n","model.add(MaxPooling1D(pool_size=2))\r\n","model.add(Conv1D(64,kernel_size=3,strides=1,\r\n","                 activation='relu'))\r\n","model.add(Conv1D(64,kernel_size=3,strides=1,\r\n","                 activation='relu'))\r\n","model.add(Conv1D(64,kernel_size=3,strides=1,\r\n","                 activation='relu'))\r\n","model.add(MaxPooling1D(pool_size=2))\r\n","model.add(Flatten())\r\n","model.add(Dense(1024,activation='relu'))\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(512,activation='relu'))\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(num_classes,activation='softmax',\r\n","               activity_regularizer=regularizers.l2(0.0002)))\r\n","\r\n","sgd=SGD(lr=0.005,decay=1e-5)\r\n","\r\n","es = tensorflow.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='auto', verbose=1, patience=5, restore_best_weights=True)\r\n","\r\n","model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\r\n","              optimizer=sgd,\r\n","              metrics=['accuracy',f1,recall,precision])\r\n","\r\n","print(model.metrics_names)\r\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DL-nCs9IYncy"},"source":["model.fit(trX,trY,batch_size=batch_size,epochs=1,validation_data=(teX,teY),verbose=1, callbacks=[es])\r\n","test_label=model.predict_classes(test_data)\r\n","print(test_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"taPXzO6br0Uu"},"source":["import numpy as np\r\n","\r\n","print(np.array(test_label).shape) \r\n","label_process=test_label.reshape(528,10)\r\n","\r\n","\r\n","label=[]\r\n","\r\n","for i in range(528):\r\n","    label.append([i+1,label_process[i][np.argmax(list(label_process[i]).count(x) for x in set(label_process[i]))]])\r\n","\r\n","import csv\r\n","with open('test_label14.csv','w',newline='') as csvfile:\r\n","    writer=csv.writer(csvfile)\r\n","    writer.writerow(['id','label'])\r\n","    for row in label:\r\n","        writer.writerow(row)\r\n"],"execution_count":null,"outputs":[]}]}